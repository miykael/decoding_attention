"""
main_01_plot.py

Plotting script for Blog Post 1 "Introduction to Attention Mechanisms with a Toy Dataset".

This script reads the CSV files generated by main_01_train.py from the results folder and produces:
  - A training loss overview plot for all models.
  - A bar chart comparing best training loss versus average validation loss.
  - A dataset example plot overlaying input and target sequences.
  - A set of individual comparative metrics plots showing model parameters, training time,
    and average inference time, as well as average validation loss.
  - Sample prediction plots (one figure per sample) showing representative predictions
    alongside input and target sequences.

Note: For meaningful sample predictions, pretrained model weights (if saved) will be loaded.
      Otherwise, a freshly instantiated StandardAttentionModel is used.
"""

import pandas as pd
import matplotlib.pyplot as plt
import torch
from pathlib import Path
import numpy as np

from data.shapes_1d import generate_shapes
from models.attention import (
    StandardAttentionModel,
    AttentionModelWithPE,
    MultiHeadAttentionModel,
)
from train.train import evaluate_model
from models.basic import FCNModel, CNNModel, LSTMModel
from config import COLORMAP, FIGURE_SIZE, DPI, VALIDATION_PLOT_SAMPLES


def plot_training_loss_overview(plots_folder: Path, results_folder: Path):
    """Plot Training Loss Overview for all models using loss history CSV."""
    loss_history_csv = results_folder / "blog_01_table_loss_history.csv"

    # Add error handling for file existence
    if not loss_history_csv.exists():
        print(f"Error: Loss history file not found at {loss_history_csv}")
        return

    # Read the CSV and print its structure for debugging
    loss_df = pd.read_csv(loss_history_csv)
    print("CSV columns:", loss_df.columns.tolist())
    print("First few rows of data:")
    print(loss_df.head())

    plt.figure(figsize=(10, 6))

    # Check if the DataFrame is already in the correct format
    if all(col in loss_df.columns for col in ["Epoch", "Model", "Loss"]):
        # Pivot the data if it's in long format
        loss_df = loss_df.pivot(index="Epoch", columns="Model", values="Loss")
    else:
        # Assume the data is already in wide format with model names as columns
        # and first column as epoch index
        loss_df.set_index(loss_df.columns[0], inplace=True)

    # Plot each model's loss
    for model in loss_df.columns:
        plt.plot(loss_df.index, loss_df[model], marker="o", label=model, alpha=0.8)

    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Blog 01: Training Loss Overview")
    plt.yscale("log")
    plt.legend()
    plt.tight_layout()

    loss_overview_path = plots_folder / "blog_01_plot_training_loss_overview.png"
    plt.savefig(loss_overview_path, dpi=DPI)
    plt.close()
    print("Training loss overview plot saved to", loss_overview_path.resolve())


def plot_combined_training_validation_loss(plots_folder: Path, results_folder: Path):
    """Plot a bar chart comparing Best Training Loss and Average Validation Loss."""
    combined_csv = results_folder / "blog_01_table_combined_results.csv"
    combined_df = pd.read_csv(combined_csv)

    plt.figure(figsize=(10, 6))
    x = range(len(combined_df))
    width = 0.35

    # Plot Best Training Loss
    plt.bar(
        x,
        combined_df["Best Training Loss"],
        width,
        alpha=0.8,
        label="Best Training Loss",
    )

    # Plot Average Validation Loss with error bars
    plt.bar(
        [xi + width for xi in x],
        combined_df["Average Validation Loss"],
        width,
        yerr=combined_df["Validation Loss Std"],
        capsize=5,
        alpha=0.8,
        label="Average Validation Loss",
    )

    plt.xticks([xi + width / 2 for xi in x], combined_df["Model"])
    plt.ylabel("Loss")
    plt.title("Blog 01: Training vs. Validation Loss")
    plt.legend()
    plt.tight_layout()

    combined_loss_path = plots_folder / "blog_01_plot_training_vs_validation_loss.png"
    plt.savefig(combined_loss_path, dpi=DPI)
    plt.close()
    print(
        "Combined training vs. validation loss plot saved to",
        combined_loss_path.resolve(),
    )


def plot_dataset_example(plots_folder: Path):
    """Plot dataset examples overlaying input and target sequences."""
    # Generate examples based on VALIDATION_PLOT_SAMPLES from config
    for idx in range(VALIDATION_PLOT_SAMPLES):
        input_seq, target_seq = generate_shapes()
        x_axis = range(len(input_seq))

        plt.figure(figsize=FIGURE_SIZE)
        plt.plot(x_axis, input_seq, label="Input Sequence", color="tab:blue", alpha=0.8)
        plt.plot(
            x_axis,
            target_seq,
            label="Target Sequence",
            color="black",
            linestyle="--",
            alpha=0.8,
        )
        plt.xlabel("Sequence Index")
        plt.ylabel("Amplitude")
        plt.title("Blog 01: Dataset Example - Input vs. Target")
        plt.legend()
        plt.tight_layout()

        dataset_example_path = (
            plots_folder / f"blog_01_plot_dataset_example_{idx + 1}.png"
        )
        plt.savefig(dataset_example_path, dpi=DPI)
        plt.close()
        print(
            f"Dataset example plot {idx + 1} saved to", dataset_example_path.resolve()
        )


def plot_comparative_metrics(plots_folder: Path, results_folder: Path):
    """
    Plot comparative metrics as separate figures:
      - Number of Parameters
      - Training Time (sec) per epoch
      - Average Inference Time (ms) with error bars
      - Average Validation Loss with error bars

    In each figure, the value of the bar is annotated above each bar.
    """
    combined_csv = results_folder / "blog_01_table_combined_results.csv"
    combined_df = pd.read_csv(combined_csv)

    # --- Plot 1: Number of Parameters ---
    plt.figure(figsize=(10, 6))
    bars = plt.bar(
        combined_df["Model"], combined_df["Parameters"], color="tab:blue", alpha=0.8
    )
    plt.title("Number of Parameters")
    plt.ylabel("Parameters")
    plt.xticks(rotation=45)
    for idx, bar in enumerate(bars):
        height = bar.get_height()
        plt.text(
            bar.get_x() + bar.get_width() / 2,
            height,
            f"{height}",
            ha="center",
            va="bottom",
        )
    plt.tight_layout()
    parameters_path = plots_folder / "blog_01_plot_parameters.png"
    plt.savefig(parameters_path, dpi=DPI)
    plt.close()
    print("Parameters plot saved to", parameters_path.resolve())

    # --- Plot 2: Training Time (sec) ---
    plt.figure(figsize=(10, 6))
    bars = plt.bar(
        combined_df["Model"],
        combined_df["Training Time per Epoch (sec)"],
        color="tab:orange",
        alpha=0.8,
    )
    plt.title("Training Time per Epoch (sec)")
    plt.ylabel("Time (sec)")
    plt.xticks(rotation=45)
    for idx, bar in enumerate(bars):
        height = bar.get_height()
        plt.text(
            bar.get_x() + bar.get_width() / 2,
            height,
            f"{height:.2f}",
            ha="center",
            va="bottom",
        )
    plt.tight_layout()
    training_time_path = plots_folder / "blog_01_plot_training_time.png"
    plt.savefig(training_time_path, dpi=DPI)
    plt.close()
    print("Training time plot saved to", training_time_path.resolve())

    # --- Plot 3: Average Inference Time (ms) with error bars ---
    plt.figure(figsize=(10, 6))
    bars = plt.bar(
        combined_df["Model"],
        combined_df["Average Inference Time (ms)"],
        yerr=combined_df["Inference Time Std (ms)"],
        capsize=5,
        color="tab:green",
        alpha=0.8,
    )
    plt.title("Average Inference Time (ms)")
    plt.ylabel("Inference Time (ms)")
    plt.xticks(rotation=45)
    for idx, bar in enumerate(bars):
        height = bar.get_height()
        plt.text(
            bar.get_x() + bar.get_width() / 2,
            height,
            f"{height:.2f}",
            ha="center",
            va="bottom",
        )
    plt.tight_layout()
    inference_time_path = plots_folder / "blog_01_plot_average_inference_time.png"
    plt.savefig(inference_time_path, dpi=DPI)
    plt.close()
    print("Average inference time plot saved to", inference_time_path.resolve())

    # --- Plot 4: Average Validation Loss with error bars ---
    plt.figure(figsize=(10, 6))
    bars = plt.bar(
        combined_df["Model"],
        combined_df["Average Validation Loss"],
        yerr=combined_df["Validation Loss Std"],
        capsize=5,
        color="tab:red",
        alpha=0.8,
    )
    plt.title("Average Validation Loss")
    plt.ylabel("Loss")
    plt.xticks(rotation=45)
    for idx, bar in enumerate(bars):
        height = bar.get_height()
        plt.text(
            bar.get_x() + bar.get_width() / 2,
            height,
            f"{height:.4f}",
            ha="center",
            va="bottom",
        )
    plt.tight_layout()
    validation_loss_path = plots_folder / "blog_01_plot_average_validation_loss.png"
    plt.savefig(validation_loss_path, dpi=DPI)
    plt.close()
    print("Average validation loss plot saved to", validation_loss_path.resolve())


def plot_sample_predictions(plots_folder: Path, results_folder: Path):
    """
    Plot sample predictions for all models in separate figures.
    For each of the validation samples:
      - Generate sample input and target sequences using generate_shapes().
      - Load pretrained weights for each model from the results folder.
      - Compute predictions for each model using evaluate_model.
      - Plot the input sequence, target sequence, and each model's prediction on a single figure.
      - Save the figure as 'blog_01_plot_sample_prediction_<sample_index>.png'.
    """
    device = torch.device("cpu")

    # Define all models.
    models_dict = {
        "FCN": FCNModel(),
        "CNN": CNNModel(),
        "LSTM": LSTMModel(),
        "Attention": StandardAttentionModel(),
        "Attention_PE": AttentionModelWithPE(),
        "MultiHeadAttention": MultiHeadAttentionModel(),
    }

    # Load weights for each model from the results folder using the proper naming.
    for model_name, model in models_dict.items():
        # Note the "model_" prefix added to match how weights are saved in main_01_train.py.
        weight_file = results_folder / f"blog_01_model_{model_name}_best_weights.pt"
        model.to(device)
        if weight_file.exists():
            model.load_state_dict(torch.load(weight_file, map_location=device))
            print(
                f"Loaded pretrained weights for {model_name} from {weight_file.resolve()}"
            )
        else:
            print(
                f"Pretrained weights not found for {model_name} at {weight_file.resolve()}. Using untrained model."
            )
        model.eval()

    num_samples = VALIDATION_PLOT_SAMPLES
    for idx in range(num_samples):
        input_seq, target_seq = generate_shapes()
        x_axis = range(len(input_seq))
        predictions = {}

        # Compute predictions for each model.
        for model_name, model in models_dict.items():
            pred, _ = evaluate_model(model, input_seq, device=device)
            pred_np = pred.cpu().detach().numpy().flatten()
            predictions[model_name] = pred_np

        plt.figure(figsize=(10, 4))

        # Plot predictions from all models.
        for model_name, pred_np in predictions.items():
            plt.plot(x_axis, pred_np, label=f"{model_name} Prediction", alpha=0.8)

        # Plot the target sequence.
        plt.plot(
            x_axis, target_seq, label="Target", color="black", linestyle="--", alpha=0.8
        )

        plt.xlabel("Sequence Index")
        plt.title(f"Sample Prediction {idx + 1}")
        plt.legend()
        plt.tight_layout()
        prediction_path = plots_folder / f"blog_01_plot_sample_prediction_{idx + 1}.png"
        plt.savefig(prediction_path, dpi=DPI)
        plt.close()
        print(f"Sample prediction plot {idx + 1} saved to", prediction_path.resolve())


def plot_positional_encoding(plots_folder: Path, max_len: int = 100, d_model: int = 16):
    """
    Plot the sinusoidal positional encoding for a given sequence length and model dimension.

    The positional encoding is computed as:
        PE(pos, 2i)   = sin(pos / (10000^(2i/d_model)))
        PE(pos, 2i+1) = cos(pos / (10000^(2i/d_model)))

    This visualization shows how the encoding varies over positions for several dimensions.

    Parameters:
        plots_folder (Path): Directory to save the generated plot.
        max_len (int): Maximum sequence length to be visualized.
        d_model (int): Dimensionality of the encoding (use a small number for clarity).
    """
    positional_enc = np.zeros((max_len, d_model))
    for pos in range(max_len):
        for idx in range(0, d_model, 2):
            positional_enc[pos, idx] = np.sin(pos / (10000 ** ((2 * idx) / d_model)))
            if idx + 1 < d_model:
                positional_enc[pos, idx + 1] = np.cos(
                    pos / (10000 ** ((2 * idx) / d_model))
                )

    plt.figure(figsize=(10, 6))
    # For clarity, plot only a subset (e.g., the first 8 dimensions) if d_model is large.
    for head in range(min(d_model, 8)):
        plt.plot(
            range(max_len),
            positional_enc[:, head],
            marker="o",
            label=f"Dimension {head}",
        )

    plt.title("Sinusoidal Positional Encoding")
    plt.xlabel("Position")
    plt.ylabel("Encoding value")
    plt.legend(ncol=2, fontsize="small")
    plt.tight_layout()
    positional_encoding_path = plots_folder / "blog_01_plot_positional_encoding.png"
    plt.savefig(positional_encoding_path, dpi=DPI)
    plt.close()
    print("Positional encoding plot saved to", positional_encoding_path.resolve())


def plot_attention_details(plots_folder: Path):
    """
    For attention-based models, generate extra plots for:
      - The attention weights for a few example inputs.
      - The query (Q), key (K), and value (V) matrices.
    """
    import matplotlib.pyplot as plt

    device = torch.device("cpu")
    # Define only the attention-based models (skip FCN, CNN, LSTM).
    models_dict = {
        "Attention": StandardAttentionModel(),
        "Attention_PE": AttentionModelWithPE(),
        "MultiHeadAttention": MultiHeadAttentionModel(),
    }

    # Load pretrained weights for each model.
    for model_name, model in models_dict.items():
        weight_file = plots_folder / f"blog_01_model_{model_name}_best_weights.pt"
        model.to(device)
        if weight_file.exists():
            model.load_state_dict(torch.load(weight_file, map_location=device))
        model.eval()

        num_samples = VALIDATION_PLOT_SAMPLES
        for sample_idx in range(num_samples):
            # Generate a sample input.
            input_seq, _ = generate_shapes()
            x = (
                torch.tensor(input_seq, dtype=torch.float32)
                .unsqueeze(0)
                .unsqueeze(0)
                .to(device)
            )
            # Forward pass with flags enabled.
            output, extra = model(x, return_attention=True, return_qkv=True)
            attention_weights, (q, k, v) = extra

            # ----- Plot Attention Weights -----
            # attention_weights shape: (1, n_heads, seq_len, seq_len)
            n_heads = attention_weights.shape[1]
            if model_name == "MultiHeadAttention":
                plt.figure(figsize=(10, n_heads * 2))
                for idx in range(n_heads):
                    plt.subplot(n_heads, 1, idx + 1)
                    plt.imshow(
                        attention_weights[0, idx].cpu().detach().numpy(),
                        aspect="auto",
                        cmap=COLORMAP,
                        interpolation="nearest",
                    )
                    plt.title(f"Head {idx + 1}")
                    plt.axis("off")
                plt.suptitle(
                    f"{model_name} - Sample {sample_idx + 1} Attention Weights"
                )
            else:
                # For standard attention: shape (1, seq_len, seq_len)
                plt.figure(figsize=(10, 3))
                plt.imshow(
                    attention_weights.squeeze(0).cpu().detach().numpy(),
                    aspect="auto",
                    cmap=COLORMAP,
                    interpolation="nearest",
                )
                plt.title(f"{model_name} - Sample {sample_idx + 1} Attention Weights")
            attn_plot_path = (
                plots_folder
                / f"blog_01_attention_{model_name}_sample_{sample_idx + 1}.png"
            )
            plt.tight_layout()
            plt.savefig(attn_plot_path, dpi=DPI)
            plt.close()
            print(f"Attention weights plot saved to {attn_plot_path.resolve()}")

            # ----- Plot Q, K, V Matrices -----
            if model_name == "MultiHeadAttention":
                n_heads = q.shape[1]
                for head in range(n_heads):
                    plt.figure(figsize=(12, 4))
                    plt.subplot(1, 3, 1)
                    plt.imshow(
                        q[0, head].cpu().detach().numpy(),
                        aspect="auto",
                        cmap=COLORMAP,
                        interpolation="nearest",
                    )
                    plt.title(f"Q Head {head + 1}")
                    plt.subplot(1, 3, 2)
                    plt.imshow(
                        k[0, head].cpu().detach().numpy(),
                        aspect="auto",
                        cmap=COLORMAP,
                        interpolation="nearest",
                    )
                    plt.title(f"K Head {head + 1}")
                    plt.subplot(1, 3, 3)
                    plt.imshow(
                        v[0, head].cpu().detach().numpy(),
                        aspect="auto",
                        cmap=COLORMAP,
                        interpolation="nearest",
                    )
                    plt.title(f"V Head {head + 1}")
                    head_qkv_plot_path = (
                        plots_folder
                        / f"blog_01_qkv_{model_name}_sample_{sample_idx + 1}_head_{head + 1}.png"
                    )
                    plt.tight_layout()
                    plt.savefig(head_qkv_plot_path, dpi=DPI)
                    plt.close()
                    print(
                        f"Q, K, V for head {head + 1} saved to {head_qkv_plot_path.resolve()}"
                    )
            else:
                plt.figure(figsize=(12, 4))
                plt.subplot(1, 3, 1)
                plt.imshow(
                    q.squeeze(0).cpu().detach().numpy(),
                    aspect="auto",
                    cmap=COLORMAP,
                    interpolation="nearest",
                )
                plt.title("Q Matrix")
                plt.subplot(1, 3, 2)
                plt.imshow(
                    k.squeeze(0).cpu().detach().numpy(),
                    aspect="auto",
                    cmap=COLORMAP,
                    interpolation="nearest",
                )
                plt.title("K Matrix")
                plt.subplot(1, 3, 3)
                plt.imshow(
                    v.squeeze(0).cpu().detach().numpy(),
                    aspect="auto",
                    cmap=COLORMAP,
                    interpolation="nearest",
                )
                plt.title("V Matrix")
                qkv_plot_path = (
                    plots_folder
                    / f"blog_01_qkv_{model_name}_sample_{sample_idx + 1}.png"
                )
                plt.tight_layout()
                plt.savefig(qkv_plot_path, dpi=DPI)
                plt.close()
                print(f"Q, K, V matrices plot saved to {qkv_plot_path.resolve()}")


def main():
    results_folder = Path("results")
    plots_folder = Path("plots")
    plots_folder.mkdir(parents=True, exist_ok=True)

    # Plot training loss overview.
    plot_training_loss_overview(plots_folder, results_folder)

    # Plot combined training vs. validation loss.
    plot_combined_training_validation_loss(plots_folder, results_folder)

    # Plot a sample dataset example.
    plot_dataset_example(plots_folder)

    # Plot comparative metrics as individual figures.
    plot_comparative_metrics(plots_folder, results_folder)

    # Plot sample predictions with the correct weight loading.
    plot_sample_predictions(plots_folder, results_folder)

    # Plot attention details.
    plot_attention_details(plots_folder)

    # Plot positional encoding.
    plot_positional_encoding(plots_folder)


if __name__ == "__main__":
    main()
